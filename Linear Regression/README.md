# Linear Regression
These are some different ways to implement machine learning linear regression!

## Specifics
In both univariate and multivariate linear regression, we implement something called the cost functiona and gradient descent.
### Cost Function
The cost function is just a function that measures the squared distance between a certain hypothesis function and the real data points. This function allows us to determine how far away (how big of an error) our hypothesis produces.
### Gradient Descent
The goal of gradient descent is to minimize the cost function. As the cost function value gets smaller, the shorter the distance between our hypothesis function data points and the real data points, the closer we are to an accurate linear function which describes our data. Gradient descent works by "stepping" in the direction which minimizes the cost function.
